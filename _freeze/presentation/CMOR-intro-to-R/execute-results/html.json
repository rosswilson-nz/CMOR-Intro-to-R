{
  "hash": "0413145ae2060224d0949da3e4eaca9a",
  "result": {
    "markdown": "---\ntitle: \"Introduction to R\"\nsubtitle: \"CMOR Lunch'n'Learn\"\nauthor: \"Ross Wilson\"\ndate: \"2023-03-08\"\ndate-format: \"D MMMM YYYY\"\nformat:\n  revealjs:\n    theme: [default, cmor.scss]\n    title-slide-attributes: \n      data-background-image: \"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\"\n      data-background-size: \"7%, 25%, 100%\"\n      data-background-position: \"3% 1%, bottom 1% left 50px,0 0\"\n      data-background-repeat: \"no-repeat\"\n    template-partials:\n      - styles.html\n      - title-slide.html\n    preview-links: auto\n    margin: 0.2\n---\n\n\n\n\n\n# Getting Started {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## What is R? What is RStudio?\n\n- R is a *programming language* designed to undertake statistical analysis\n- RStudio is an Integrated Development Environment (IDE) for R\n  - An IDE is a piece of software including a text editor and other tools to make programming (in this case programming in R, specifically) easier\n  - You don’t need to use RStudio to use R, but it makes it ***a lot*** easier\n  - To use RStudio, you also need R installed and working\n\n## Why learn R?\n\n- Powerful and extensible\n  - Pretty much any statistical analysis you want to do can be done in R\n  - There are a huge number of freely-available user-written packages that provide all sorts of additional functionality\n- Reproducibility\n  - By writing R scripts (code) for your analyses, they can be easily checked/replicated/ updated/adapted, by yourself and others\n- High-quality graphics\n  - R has a lot of plotting functions to help you produce publication-quality figures\n\n\n## Getting set up\n\n- Install R\n  - <https://cloud.R-project.org/>\n  - Choose the appropriate version for your operating system and follow the instructions\n- Install RStudio\n  - <https://posit.co/download/rstudio-desktop/>\n  - ditto\n\n## Getting to know RStudio\n\n:::{.absolute}\n![](images/rstudio-screenshot.png)\n:::\n\n:::{.fragment}\n:::{.absolute top=\"155\" left=\"0\" width=\"609\" height=\"161\" style=\"border-style:solid; border-width:5px; border-color:red; background: rgba(255, 255, 255, 0.4);\"}\n:::\n:::{.absolute top=\"205\" left=\"0\" width=\"609\" height=\"50\" style=\"text-align:center; color:red; font-weight:bold;\"}\nSource\n:::\n:::\n\n:::{.fragment}\n:::{.absolute top=\"321\" left=\"0\" width=\"609\" height=\"311\" style=\"border-style:solid; border-width:5px; border-color:red; background: rgba(255, 255, 255, 0.4);\"}\n:::\n:::{.absolute top=\"425\" left=\"0\" width=\"609\" style=\"text-align:center; color:red; font-weight:bold;\"}\nConsole\n:::\n:::\n\n:::{.fragment}\n:::{.absolute top=\"155\" left=\"614\" width=\"373\" height=\"180\" style=\"border-style:solid; border-width:5px; border-color:red; background: rgba(255, 255, 255, 0.4);\"}\n:::\n:::{.absolute top=\"190\" left=\"614\" width=\"373\" style=\"text-align:center; color:red; font-weight:bold;\"}\nEnvironment/<br>History\n:::\n:::\n\n:::{.fragment}\n:::{.absolute top=\"340\" left=\"614\" width=\"373\" height=\"292\" style=\"border-style:solid; border-width:5px; border-color:red; background: rgba(255, 255, 255, 0.4);\"}\n:::\n:::{.absolute top=\"405\" left=\"614\" width=\"373\" style=\"text-align:center; color:red; font-weight:bold;\"}\nFiles/Plots/<br>Packages/<br>Help/Viewer\n:::\n:::\n\n## Starting with R\n\n. . .\n\n- We can type math in the console, and get an answer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n3+5\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8\n```\n:::\n:::\n\n\n. . .\n\n- But to do anything useful, we need to assign the result to a name:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|2\"}\nx <- 3 + 5\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8\n```\n:::\n:::\n\n\n![](images/environment-pane.png){.absolute .fragment top=300 left=250}\n\n## Starting with R\n\n. . .\n\n- Then we can do things with them:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- 2 * x\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 16\n```\n:::\n:::\n\n\n![](images/environment-pane-2.png){.absolute .fragment top=115 left=250}\n\n. . .\n\n<br>\n\n- But note that once the value is assigned to y, changing x will not update y:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 25\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 16\n```\n:::\n:::\n\n\n## Functions\n\n- Functions allow us to run commands other than simple arithmetic\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\n- Functions consist of a set of input *arguments*, code that does something with those inputs, and a return *value*\n\n. . .\n\n- To get help on a function, look up the documentation\n\n```{.r}\n?sqrt\n```\n\n![](images/function-documentation.png){.absolute .fragment top=10 left=500}\n\n## Functions\n\n- You can (and should!) also write your own functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntimes2 <- function(a) {\n\treturn(a * 2)\n}\ntimes2(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 50\n```\n:::\n:::\n\n\n. . .\n\n- Separating your code out into discrete functions makes it\n  - shorter\n  - easier to follow\n  - less error prone\n\n## Data types\n\n- So far we have only seen single numeric values\n- Data in R can take many forms\n  - The most basic data structure is the *vector*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- c(3, 7, 10, 6)\nz\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  3  7 10  6\n```\n:::\n:::\n\n\n. . .\n\n- Vectors can also contain characters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(\"apple\", \"banana\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"apple\"  \"banana\"\n```\n:::\n:::\n\n\n:::{.absolute .fragment .smaller top=400 left=300 width=500 style=\"background:#ffffff; border-style:solid; border-width:medium; border-color:red; font-size:0.7em;\"}\n**The quotes are essential:**\n\notherwise R will look for the names 'apple' and 'banana' (if these names exist, it will use the values they refer to instead of the character strings; if they don't, it will give an error)\n:::\n\n## Data types\n\n- The basic data types are `numeric`, `character`, `logical` (`TRUE` and `FALSE` values only), and `integer`\n  - Also `complex` and `raw`, but we don't need to worry about those\n- In addition to vectors, more complex data structures include:\n  - lists: similar to vectors, but the elements can be anything (including other lists), and don't need to all be the same\n  - matrices and arrays: like vectors, but with multiple dimensions\n  - data frames: more on these later\n\n## Subsetting\n\n- We can extract values from within a vector (or other data structure) with square brackets\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- c(4, 2, 5, 12)\na[c(4, 2)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12  2\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\na[c(TRUE, FALSE, TRUE, FALSE)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4 5\n```\n:::\n:::\n\n\n- We can use this in conjunction with a logical operator to do conditional subsetting\n\n\n::: {.cell}\n\n```{.r .cell-code}\na[a > 4]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  5 12\n```\n:::\n:::\n\n\n# Working with Data Frames {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Data frames\n\n- A data frame is a tabular data structure (like a spreadsheet)\n  - Each column is a variable\n  - Each row is an observation\n- Each column (variable) is a vector, so must contain a single data type\n  - But different columns can have different types\n- We can read data from Excel or CSV spreadsheets, data files from Stata etc, previously saved R data frames, and much else...\n\n## The `tidyverse`\n\n- The '`tidyverse`' is a collection of packages created by the company that makes RStudio\n- It contains a lot of functions designed to make working with data frames easier\n  - `tibble`: a replacement for base data frames\n  - `readr`: read tabular data like csv files (also `readxl` for Excel files, `haven` for SPSS/Stata/SAS, and others for different file types)\n  - `dplyr`: data manipulation\n  - `tidyr`: reshaping and tidying data\n  - `ggplot2`: creating plots\n  - `purrr`: functional programming\n  - `stringr`: working with character strings\n  - `forcats`: working with factor variables\n\n## Data frames\n\n- Reading in a data frame with `read_csv()`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ngapminder <- read_csv(here::here(\"raw_data/gapminder_data.csv\"))\ngapminder\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 6\n   country      year      pop continent lifeExp gdpPercap\n   <chr>       <dbl>    <dbl> <chr>       <dbl>     <dbl>\n 1 Afghanistan  1952  8425333 Asia         28.8      779.\n 2 Afghanistan  1957  9240934 Asia         30.3      821.\n 3 Afghanistan  1962 10267083 Asia         32.0      853.\n 4 Afghanistan  1967 11537966 Asia         34.0      836.\n 5 Afghanistan  1972 13079460 Asia         36.1      740.\n 6 Afghanistan  1977 14880372 Asia         38.4      786.\n 7 Afghanistan  1982 12881816 Asia         39.9      978.\n 8 Afghanistan  1987 13867957 Asia         40.8      852.\n 9 Afghanistan  1992 16317921 Asia         41.7      649.\n10 Afghanistan  1997 22227415 Asia         41.8      635.\n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - `select()` only a subset of variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(gapminder, year, country, gdpPercap)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 3\n    year country     gdpPercap\n   <dbl> <chr>           <dbl>\n 1  1952 Afghanistan      779.\n 2  1957 Afghanistan      821.\n 3  1962 Afghanistan      853.\n 4  1967 Afghanistan      836.\n 5  1972 Afghanistan      740.\n 6  1977 Afghanistan      786.\n 7  1982 Afghanistan      978.\n 8  1987 Afghanistan      852.\n 9  1992 Afghanistan      649.\n10  1997 Afghanistan      635.\n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - `filter()` only a subset of observations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(gapminder, continent == \"Europe\", year == 2007)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 x 6\n   country                 year      pop continent lifeExp gdpPercap\n   <chr>                  <dbl>    <dbl> <chr>       <dbl>     <dbl>\n 1 Albania                 2007  3600523 Europe       76.4     5937.\n 2 Austria                 2007  8199783 Europe       79.8    36126.\n 3 Belgium                 2007 10392226 Europe       79.4    33693.\n 4 Bosnia and Herzegovina  2007  4552198 Europe       74.9     7446.\n 5 Bulgaria                2007  7322858 Europe       73.0    10681.\n 6 Croatia                 2007  4493312 Europe       75.7    14619.\n 7 Czech Republic          2007 10228744 Europe       76.5    22833.\n 8 Denmark                 2007  5468120 Europe       78.3    35278.\n 9 Finland                 2007  5238460 Europe       79.3    33207.\n10 France                  2007 61083916 Europe       80.7    30470.\n# ... with 20 more rows\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - `mutate()` to create new variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmutate(gapminder, gdp_billion = gdpPercap * pop / 10^9)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 7\n   country      year      pop continent lifeExp gdpPercap gdp_billion\n   <chr>       <dbl>    <dbl> <chr>       <dbl>     <dbl>       <dbl>\n 1 Afghanistan  1952  8425333 Asia         28.8      779.        6.57\n 2 Afghanistan  1957  9240934 Asia         30.3      821.        7.59\n 3 Afghanistan  1962 10267083 Asia         32.0      853.        8.76\n 4 Afghanistan  1967 11537966 Asia         34.0      836.        9.65\n 5 Afghanistan  1972 13079460 Asia         36.1      740.        9.68\n 6 Afghanistan  1977 14880372 Asia         38.4      786.       11.7 \n 7 Afghanistan  1982 12881816 Asia         39.9      978.       12.6 \n 8 Afghanistan  1987 13867957 Asia         40.8      852.       11.8 \n 9 Afghanistan  1992 16317921 Asia         41.7      649.       10.6 \n10 Afghanistan  1997 22227415 Asia         41.8      635.       14.1 \n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - `summarise()` to calculate summary statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarise(gapminder, mean_gdpPercap = mean(gdpPercap))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 1\n  mean_gdpPercap\n           <dbl>\n1          7215.\n```\n:::\n:::\n\n\n. . .\n\n - This is most useful in conjunction with `group_by()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarise(group_by(gapminder, continent),\n\t\t\t\t\tmean_gdpPercap = mean(gdpPercap))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  continent mean_gdpPercap\n  <chr>              <dbl>\n1 Africa             2194.\n2 Americas           7136.\n3 Asia               7902.\n4 Europe            14469.\n5 Oceania           18622.\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - The power of `dplyr` is in combining several commands using 'pipes'\n  \n  - The previous command could be written:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder %>% \n\tgroup_by(continent) %>% \n\tsummarise(mean_gdpPercap = mean(gdpPercap))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  continent mean_gdpPercap\n  <chr>              <dbl>\n1 Africa             2194.\n2 Americas           7136.\n3 Asia               7902.\n4 Europe            14469.\n5 Oceania           18622.\n```\n:::\n:::\n\n\n## Reshaping data frames\n\n- Previously we said that data frames have variables in columns and observations in rows\n- There may be different ways to interpret this in any given dataset\n  - Our dataset has country-by-year as the observation, and population, life expectancy, and GDP per capita as variables\n  - Sometimes it might make sense to have one row per country (observation), and multiple variables representing years\n  - These are known as 'long' and 'wide' format, respectively\n\n## Reshaping data frames\n\n- The `tidyr` package helps us transform our data from one shape to the other\n  + `pivot_wider()` takes a long dataset and makes it wider\n  + `pivot_longer()` takes a wide dataset and makes it longer\n- Recall our original dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 6\n   country      year      pop continent lifeExp gdpPercap\n   <chr>       <dbl>    <dbl> <chr>       <dbl>     <dbl>\n 1 Afghanistan  1952  8425333 Asia         28.8      779.\n 2 Afghanistan  1957  9240934 Asia         30.3      821.\n 3 Afghanistan  1962 10267083 Asia         32.0      853.\n 4 Afghanistan  1967 11537966 Asia         34.0      836.\n 5 Afghanistan  1972 13079460 Asia         36.1      740.\n 6 Afghanistan  1977 14880372 Asia         38.4      786.\n 7 Afghanistan  1982 12881816 Asia         39.9      978.\n 8 Afghanistan  1987 13867957 Asia         40.8      852.\n 9 Afghanistan  1992 16317921 Asia         41.7      649.\n10 Afghanistan  1997 22227415 Asia         41.8      635.\n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Reshaping data frames\n\n- We can reshape this to be wider (one row per country)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder_wide <- gapminder %>% \n  pivot_wider(id_cols = c(country, continent),\n              names_from = year, values_from = c(pop, lifeExp, gdpPercap))\ngapminder_wide\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 142 x 38\n   country     continent pop_1952 pop_1957 pop_1962 pop_1967 pop_1972 pop_1977\n   <chr>       <chr>        <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n 1 Afghanistan Asia       8425333  9240934 10267083 11537966 13079460 14880372\n 2 Albania     Europe     1282697  1476505  1728137  1984060  2263554  2509048\n 3 Algeria     Africa     9279525 10270856 11000948 12760499 14760787 17152804\n 4 Angola      Africa     4232095  4561361  4826015  5247469  5894858  6162675\n 5 Argentina   Americas  17876956 19610538 21283783 22934225 24779799 26983828\n 6 Australia   Oceania    8691212  9712569 10794968 11872264 13177000 14074100\n 7 Austria     Europe     6927772  6965860  7129864  7376998  7544201  7568430\n 8 Bahrain     Asia        120447   138655   171863   202182   230800   297410\n 9 Bangladesh  Asia      46886859 51365468 56839289 62821884 70759295 80428306\n10 Belgium     Europe     8730405  8989111  9218400  9556500  9709100  9821800\n# ... with 132 more rows, and 30 more variables: pop_1982 <dbl>,\n#   pop_1987 <dbl>, pop_1992 <dbl>, pop_1997 <dbl>, pop_2002 <dbl>,\n#   pop_2007 <dbl>, lifeExp_1952 <dbl>, lifeExp_1957 <dbl>, lifeExp_1962 <dbl>,\n#   lifeExp_1967 <dbl>, lifeExp_1972 <dbl>, lifeExp_1977 <dbl>,\n#   lifeExp_1982 <dbl>, lifeExp_1987 <dbl>, lifeExp_1992 <dbl>,\n#   lifeExp_1997 <dbl>, lifeExp_2002 <dbl>, lifeExp_2007 <dbl>,\n#   gdpPercap_1952 <dbl>, gdpPercap_1957 <dbl>, gdpPercap_1962 <dbl>, ...\n```\n:::\n:::\n\n\n## Reshaping data frames\n\n- Often raw data will come in a wide format, and we want to reshape it longer for data analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder_wide %>% \n  pivot_longer(pop_1952:gdpPercap_2007,\n               names_to = c(\".value\", \"year\"), names_sep = \"_\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 6\n   country     continent year       pop lifeExp gdpPercap\n   <chr>       <chr>     <chr>    <dbl>   <dbl>     <dbl>\n 1 Afghanistan Asia      1952   8425333    28.8      779.\n 2 Afghanistan Asia      1957   9240934    30.3      821.\n 3 Afghanistan Asia      1962  10267083    32.0      853.\n 4 Afghanistan Asia      1967  11537966    34.0      836.\n 5 Afghanistan Asia      1972  13079460    36.1      740.\n 6 Afghanistan Asia      1977  14880372    38.4      786.\n 7 Afghanistan Asia      1982  12881816    39.9      978.\n 8 Afghanistan Asia      1987  13867957    40.8      852.\n 9 Afghanistan Asia      1992  16317921    41.7      649.\n10 Afghanistan Asia      1997  22227415    41.8      635.\n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Other `tidyverse` packages\n\n- We'll come back to data visualisation with `ggplot2` in a later session\n- `purrr` provides tools for functional programming\n  - If we have several similar datasets, or subgroups within our dataset, we don't want to write out/copy-and-paste our code separately for each one\n  - With `purrr`, we can use `map()` (and similar) to apply a function to multiple inputs and extract all of the outputs\n- `stringr` and `forcats` are worth looking at if you need to work with string or factor variables -- we won't cover them here\n\n## Resources\n\n- This material was adapted from the Data Carpentries' 'R for Social Scientists' course (<https://preview.carpentries.org/r-socialsci/index.html>)\n- Hands-On Programming with R (<https://rstudio-education.github.io/hopr>)\n  - An introduction to programming in R (for non-programmers!)\n- R for Data Science (<https://r4ds.hadley.nz>)\n  - An excellent practical introduction to using the tidyverse\n- Advanced R (<https://adv-r.hadley.nz>) and R Packages (<https://r-pkgs.org>)\n  - More advanced -- good next steps once you're a bit more comfortable using R\n\n# Data analysis in R (regression) {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Everything in R is an object\n\n. . .\n\n* This includes your fitted regression models\n\n. . .\n\n* Workflow:\n  * Import/tidy/manipulate raw data\n  * Run regression or other models\n  * Use the created model objects\n    * print to console\n    * save to file\n    * extract coefficient estimates\n    * plot results\n    * export to excel/word\n    * etc.\n\n## Fitted model objects\n\n* R has evolved over time to fit a variety of different needs and use cases\n\n* This gives it great flexibility and ability to meet the needs of different users\n\n* But, the diversity of interfaces, data structures, implementation, and fitted model objects can be a challenge\n  * There is often more than one way to fit a given model\n  * What you've learned about one model implemented in a given package may not translate well to working with other functions/packages\n\n* We'll cover some tools to help bridge that gap\n\n## Fitted model objects\n\n* A few common (but not universal) features:\n\n* Models are described by a `formula`: e.g. `y ~ x + z`\n\n* Data are provided in a data frame (or, equivalently, tibble)\n\n* `coef()`, `vcov()`, `summary()` can be used to extract the coefficient estimates, variance covariance matrix, and to print a summary of the fitted model\n\n## The `broom` package\n\n* `broom` provides several functions to convert fitted model objects to tidy tibbles\n\n* The package works with several model fitting functions from base R and commonly-used packages\n\n  * Some other packages may also implement their own methods to work with these functions\n\n* Functions:\n  * `tidy()`: construct a tibble that summarises the statistical findings (coefficients, p-values, etc.)\n  * `augment()`: add new columns to the original data (predictions/fitted values, etc.)\n  * `glance()`: construct a one-row summary of the model (goodness-of-fit, etc.)\n\n## First example -- linear regression\n\n* Linear regression models can be fitted with the `lm` function (in the `stats` package, part of base R)\n\n\n* We'll start by loading the gapminder dataset from the previous session:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ngapminder <- read_csv(here::here(\"raw_data/gapminder_data.csv\"))\n```\n:::\n\n\n## First example -- linear regression\n\n* Use `?lm` to find the documentation\n\n\n:::{.fragment fragment-index=2}\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlinear_regression_model <- lm(lifeExp ~ gdpPercap, gapminder)\nlinear_regression_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = lifeExp ~ gdpPercap, data = gapminder)\n\nCoefficients:\n(Intercept)    gdpPercap  \n  5.396e+01    7.649e-04  \n```\n:::\n:::\n\n:::\n\n![](images/lm-documentation.png){.absolute .fragment fragment-index=1 top=50 left=700}\n\n## First example -- linear regression\n\n* `linear_regression_model` is now a fitted model object\n\n* If we want, we can look at how this object is actually stored:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(linear_regression_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 12\n $ coefficients : Named num [1:2] 5.40e+01 7.65e-04\n  ..- attr(*, \"names\")= chr [1:2] \"(Intercept)\" \"gdpPercap\"\n $ residuals    : Named num [1:1704] -25.8 -24.3 -22.6 -20.6 -18.4 ...\n  ..- attr(*, \"names\")= chr [1:1704] \"1\" \"2\" \"3\" \"4\" ...\n $ effects      : Named num [1:1704] -2455.1 311.1 -21.6 -19.6 -17.5 ...\n  ..- attr(*, \"names\")= chr [1:1704] \"(Intercept)\" \"gdpPercap\" \"\" \"\" ...\n $ rank         : int 2\n $ fitted.values: Named num [1:1704] 54.6 54.6 54.6 54.6 54.5 ...\n  ..- attr(*, \"names\")= chr [1:1704] \"1\" \"2\" \"3\" \"4\" ...\n $ assign       : int [1:2] 0 1\n $ qr           :List of 5\n  ..$ qr   : num [1:1704, 1:2] -41.2795 0.0242 0.0242 0.0242 0.0242 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : chr [1:1704] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. ..$ : chr [1:2] \"(Intercept)\" \"gdpPercap\"\n  .. ..- attr(*, \"assign\")= int [1:2] 0 1\n  ..$ qraux: num [1:2] 1.02 1.02\n  ..$ pivot: int [1:2] 1 2\n  ..$ tol  : num 1e-07\n  ..$ rank : int 2\n  ..- attr(*, \"class\")= chr \"qr\"\n $ df.residual  : int 1702\n $ xlevels      : Named list()\n $ call         : language lm(formula = lifeExp ~ gdpPercap, data = gapminder)\n $ terms        :Classes 'terms', 'formula'  language lifeExp ~ gdpPercap\n  .. ..- attr(*, \"variables\")= language list(lifeExp, gdpPercap)\n  .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:2] \"lifeExp\" \"gdpPercap\"\n  .. .. .. ..$ : chr \"gdpPercap\"\n  .. ..- attr(*, \"term.labels\")= chr \"gdpPercap\"\n  .. ..- attr(*, \"order\")= int 1\n  .. ..- attr(*, \"intercept\")= int 1\n  .. ..- attr(*, \"response\")= int 1\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. ..- attr(*, \"predvars\")= language list(lifeExp, gdpPercap)\n  .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n  .. .. ..- attr(*, \"names\")= chr [1:2] \"lifeExp\" \"gdpPercap\"\n $ model        :'data.frame':\t1704 obs. of  2 variables:\n  ..$ lifeExp  : num [1:1704] 28.8 30.3 32 34 36.1 ...\n  ..$ gdpPercap: num [1:1704] 779 821 853 836 740 ...\n  ..- attr(*, \"terms\")=Classes 'terms', 'formula'  language lifeExp ~ gdpPercap\n  .. .. ..- attr(*, \"variables\")= language list(lifeExp, gdpPercap)\n  .. .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : chr [1:2] \"lifeExp\" \"gdpPercap\"\n  .. .. .. .. ..$ : chr \"gdpPercap\"\n  .. .. ..- attr(*, \"term.labels\")= chr \"gdpPercap\"\n  .. .. ..- attr(*, \"order\")= int 1\n  .. .. ..- attr(*, \"intercept\")= int 1\n  .. .. ..- attr(*, \"response\")= int 1\n  .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. .. ..- attr(*, \"predvars\")= language list(lifeExp, gdpPercap)\n  .. .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n  .. .. .. ..- attr(*, \"names\")= chr [1:2] \"lifeExp\" \"gdpPercap\"\n - attr(*, \"class\")= chr \"lm\"\n```\n:::\n:::\n\n\n## First example -- linear regression\n\n* More usefully, we can print a summary of the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(linear_regression_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = lifeExp ~ gdpPercap, data = gapminder)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-82.754  -7.758   2.176   8.225  18.426 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 5.396e+01  3.150e-01  171.29   <2e-16 ***\ngdpPercap   7.649e-04  2.579e-05   29.66   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.49 on 1702 degrees of freedom\nMultiple R-squared:  0.3407,\tAdjusted R-squared:  0.3403 \nF-statistic: 879.6 on 1 and 1702 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## First example -- linear regression\n\n* If we want to work with the results or combine/compare them with other models, `tidy()` from the `broom` package will put them into a nice tidy tibble\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\ntidy(linear_regression_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept) 54.0      0.315         171.  0        \n2 gdpPercap    0.000765 0.0000258      29.7 3.57e-156\n```\n:::\n:::\n\n\n. . .\n\n* And `glance()` gives us several overall model statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(linear_regression_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik    AIC    BIC\n      <dbl>         <dbl> <dbl>     <dbl>     <dbl> <dbl>  <dbl>  <dbl>  <dbl>\n1     0.341         0.340  10.5      880. 3.57e-156     1 -6422. 12850. 12867.\n# ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\n# Data visualisation {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Data visualisation with `ggplot2`\n\n- There are a lot of tools available to create plots in R\n  - `ggplot2` is the most well-developed and widely used\n- We generally want data in long format for plotting\n  - One column for each variable\n  - One row for each observation\n- We'll use the `gapminder` dataset from the previous session\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ngapminder <- read_csv(here::here(\"raw_data/gapminder_data.csv\"))\n```\n:::\n\n\n## The grammar of graphics\n\n- dataset -- self-explanatory\n- geom -- the geometric object used to represent the data\n- mappings -- which features of the geom represent which variables in the data\n- stats -- transformations of the data before plotting\n- position -- to avoid overplotting data points\n- coordinate system -- how the x and y axes are plotted\n- faceting scheme -- split the plot by subgroups\n\n## Data visualisation with `ggplot2` {.smaller}\n\n- That's the theory\n- In practice, the easiest way is to build the plot up step-by-step (trial-and-error)\n  - start with the basic `ggplot` object\n\n```{.r}\nggplot(data = gapminder)\n```\n\n:::{.fragment fragment-index=1}\n![](images/ggplot-blank.png){.absolute .fragment fragment-index=2 .fade-out top=100 left=200 width=550 height=550}\n:::\n\n:::{.fragment fragment-index=2}\n- you can specify (some of) the mappings at this stage\n\n```{.r}\nggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))\n```\n:::\n\n::: {.fragment .fade-in fragment-index=3}\n![](images/ggplot-axes.png){.absolute .fragment .fade-out top=100 left=200 width=550 height=550}\n:::\n\n# Data analysis workflows and project organisation {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Reproducible research\n\n* What is 'reproducibility'?\n  * Focus here is on *computational reproducibility* -- can your results be replicated by someone (or yourself!) with access to your data, code, etc.\n\n* Why might research not be reproducible?\n  * Raw data are not available or have been changed\n  * Intermediate steps taken to extract, clean, reshape, merge, or analyse data are not adequately recorded or described\n  * Software tools have changed or are no longer available since the analysis was conducted\n  * Errors in manually transcribing results from analysis software to final report (manuscript, etc.)\n\n## Reproducible research\n\n* Ensuring reproducibility (for others) can also have great benefits for you as the analyst/author\n  * When you come back to an analysis later, you know exactly what you did, why you did it, and how to replicate it if needed\n  * If data changes, errors are identified, or new analyses need to be conducted, your analysis and results can easily be updated\n  * The code and methods used in one project/analysis can be re-used in other work\n  * Keeping to a simple, standardised workflow for all projects allows you to switch easily & quickly between projects\n    * And prevents you having to make a whole bunch of new decisions every time you start something new\n\n---\n\n![](images/interconnected-tasks.png)\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles -- Raw data\n\n* Raw data stays raw\n  * Make raw data files read-only\n  \n## Key principles - Raw data\n\n![](images/read-only.png)\n\n## Key principles -- Raw data\n\n* Raw data stays raw\n  * Make raw data files read-only\n  * Can be relaxed (temporarily) if needed, but avoids accidental changes\n  * Most (probably all) changes to data should be scripted (in R, Stata, etc.) rather than made directly in raw data files\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles\n\n* Raw data stays raw\n* [Source is real]{style=\"color:Red;\"}\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles -- Source files\n\n* Source is real...\n  * ...workspace is replaceable\n* Any individual R session is disposable and can be replaced/recreated at any time, if you have raw data and appropriate source code\n* Thinking in this way forces you to follow good reproducibility practices in your analysis workflow\n\n## Key principles -- Source files\n\n* What does 'Source is real' mean?\n  * Data import, cleaning, reshaping, wrangling, and analysis should all be conducted via script files\n    * or at least documented in thorough, step-by-step detail\n  * All source code should be saved (regularly!) so all of these steps can be reproduced at any time\n  * Important (or time-consuming) intermediate objects (cleaned datasets, figures, etc) should be explicitly saved, individually, to files (by script, not the mouse, if possible)\n\n## Key principles -- Source files\n\n* Start R with a blank slate, and restart often\n\n## Key principles -- Source files\n\n![](images/save-workspace.PNG)\n\n:::{.absolute top=\"330\" left=\"130\" width=\"260\" height=\"72\" style=\"border-style:solid; border-width:5px; border-color:red;\"}\n:::\n\n## Key principles -- Source files\n\n* Start R with a blank slate, and restart often\n  * When you are running code interactively to try things out, you will be adding objects to the workspace, loading packages, etc\n  * If you inadvertently rely on these objects, packages, etc in your source files, you may not be able to reproduce your results in a new session later\n  * If you have saved source code and intermediate objects to file as you go, it is quick and easy to restart R (Ctrl+Shift+F10, in RStudio) regularly to check whether everything still works as expected\n    * It is much better to find this out after a few minutes than after a whole day’s work!\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* [Design for collaboration]{style=\"color:Red;\"}\n  * [(including with your future self)]{style=\"color:Red;\"}\n* Consider version control\n* Automation?\n\n## Key principles -- Design for collaboration\n\n. . .\n\n* An analysis directory like this makes it very difficult for anyone (including yourself later) to follow the steps required to reproduce your results\n\n---\n\n![](images/bad_layout.png)\n\n## Key principles -- Design for collaboration\n\n:::{.columns}\n\n::: {.column}\n* Much better to follow a logical structure (and the same across all of your projects)\n  * Set out high-level structure, e.g.\n    1. read raw data\n    2. tidy data for analysis\n    3. run analyses on tidy data\n    4. collate report/results of analyses\n  * Put raw data in its own directory (and read-only)\n  * Consider other structures/subfolders as appropriate for your project\n:::\n\n:::{.column}\n![](images/better-layout.png)\n:::\n\n:::\n\n## Key principles -- Design for collaboration\n\n* Break up complicated or repeated analysis steps into discrete functions\n* Give functions and variables meaningful names\n* Use comments liberally\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* [Consider version control]{style=\"color:Red;\"}\n* Automation?\n\n## Key principles -- Version control\n\n* Keeping track of changes to data and code (and being able to revert to a previous version if things go wrong) is critical for reproducible research\n\n* This is particularly true when collaborating with others\n\n* The best way to do this is with a version control system such as Git\n\n## Key principles -- Version control\n\n* We won't go into this in detail today, but a quick Getting Started guide:\n  * Register a GitHub account (<https://github.com>)\n  * Install Git (<https://git-scm.com>) and complete basic setup\n  * Get a Git client (GUI)\n    * GitKraken is a good choice (<https://gitkraken.com>)\n    * GitHub offers a free client, GitHub Desktop (<https://desktop.github.com/>)\n    * RStudio has a basic Git client built-in, which is fine for much day-to-day use\n* See <https://happygitwithr.com/> for more detailed instructions\n\n## Key principles -- Version control\n\n* Using Git (& GitHub) in your projects\n  * A couple of ways to get this set up. Probably the easiest is:\n  * Create a project repository (repo) on GitHub\n  * Import ('clone') the repo as a new RStudio project\n  * Make changes as usual in RStudio (or nay other program)\n  * 'Commit' (take a snapshop of the current state of the project) often to your local repo\n  * Less often (maybe once/day) 'push' (sync) the local repo to GitHub\n* What to put under version control\n  * Source code\n  * Raw data (unless its very large)\n\n:::{.absolute .fragment top=480 left=500 width=500 style=\"background:#ffffff; border-style:solid; border-width:medium; border-color:red; font-size:0.9em; margin-left:20px; line-height:0.9;\"}\nWhat **not** to put under version control\n\n* Most intermediate objects\n* Miscellaneous supporting documents (pdf files, etc.)\n* Final output in the form of word documents, etc.\n:::\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* [Automation?]{style=\"color:Red;\"}\n\n## Key principles -- Automation\n\n* Just as we treat source code as the ‘true’, reproducible record of each step of the analysis, we can record (and automate) how the sequence of individual steps fits together to produce our final results\n\n::: {.fragment fragment-index=1}\n::: {.fragment .fade-out fragment-index=2}\n![](images/workflow.png){.absolute top=100 left=333}\n:::\n:::\n\n:::{.fragment fragment-index=2}\n\n* Can be as simple as something like:\n\n\t```{.r}\n\tsource(\"code/00-download-data.R\")\n\tsource(\"code/01-tabulate-frequencies.R\")\n\tsource(\"code/02-create-histogram.R\")\n\tsource(\"code/03-render-report.R\")\n\t```\n\n* Shows in what order to run the scripts, and allows us to resume from the middle (if, for example, you have only changed the file `02-create-histogram.R`, there is no need to redo the first two steps, but we do need to rerun the `create-histogram` and `render-report` steps\n  * Each script should load the required inputs and save the resulting output to file\n\n:::\n\n## Key principles -- Automation\n\n* For more complicated (or long-running) analyses, we may want to explicitly specify dependencies and let the computer figure out how to get everything up-to-date\n\n* Two good tools for doing this:\n  * make\n  * targets\n\n* Advantages of an automated pipeline like this:\n  * When you modify one stage of the pipeline, you can re-run your analyses to get up-to-date final results, with a single click/command\n  * Only the things that need to be updated will be re-run, saving time (important if some of your analyses take a long time to run)\n\n## Key principles -- Automation\n\n* Make is a system tool, designed for use in software development, to specify targets, commands, and dependencies between files and selectively re-run commands when dependencies change\n\n* A Makefile is a plain text file specifying a list of these targets (intermediate/output files in the analysis workflow), commands (to create the targets), and dependencies (input files needed for each command)\n\n```{.bash}\nwords.txt: /usr/share/dict/words\n\tcp /usr/share/dict/words words.txt\n\nhistogram.tsv: histogram.r words.txt\n\tRscript $<\n\nhistogram.png: histogram.tsv\n\tRscript -e 'library(ggplot2); qplot(Length, Freq, data=read.delim(\"$<\")); ggsave(\"$@\")'\n\nreport.html: report.rmd histogram.tsv histogram.png\n\tRscript -e 'rmarkdown::render(\"$<\")'\n```\n\n## Key principles -- Automation\n\n* `targets` is an R package designed to do something very similar, but specifically designed for R projects\n\n```{.r}\nplan <- list(\n  tar_file(words, download_words()),\n  tar_target(frequency_table, summarise_word_lengths(words)),\n  tar_target(histogram, create_histogram(frequency_table)),\n  tar_file(report, render_report(\"reports/report.rmd\", frequency_table, histogram))\n)\n```\n\n* Abstract workflow steps behind function calls (with meaningful names) as much as possible\n  * The plan should be a clear, high-level overview of the analysis steps required\n\n## Summary\n\n* Treat raw data as read-only\n* Save source, not the workspace\n* Design for collaboration\n  * Follow a logical project structure\n  * Simplify code with human-readable abstractions (functions etc)\n* Consider version control\n* Consider automating your analyses\n\n---\n\n![](images/owl.jpg)\n\n## Summary\n\n* Treat raw data as read-only ![](images/tick.jpg){style=\"height:1em\"}\n* Save source, not the workspace ![](images/tick.jpg){style=\"height:1em\"}\n* Design for collaboration\n  * Follow a logical project structure ![](images/tick.jpg){style=\"height:1em\"}\n  * Simplify code with human-readable abstractions (functions etc) ![](images/tick.jpg){style=\"height:1em\"}\n* Consider version control\n* Consider automating your analyses\n\n:::{.absolute top=120 left=540 style=\"color:#0070c0; font-size:0.6em; line-height:0.6em;\"}\n(if you are already writing<br>script files for your analyses)\n:::\n\n:::{.absolute top=325 left=800 style=\"color:#0070c0; font-size:0.6em; line-height:0.6em;\"}\n(will get better<br>with practice)\n:::\n\n## Resources {.smaller}\n\n* Wilson G, Aruliah DA, Brown CT, Chue Hong NP, Davis M, et al. (2014) Best Practices for Scientific Computing. PLoS Biol 12(1):e1001745. <https://doi.org/10.1371/journal.pbio.1001745>\n* Wilson G, Bryan J, Cranston K, Kitzes J, Nederbragt L, Teal TK (2017) Good enough practices in scientific computing. PloS Comput Biol 13(6):e1005510. <https://doi.org/10.1371/journal.pcbi.1005510>\n* Bryan J, Hester J. What they forgot to teach you about R. <https://rstats.wtf> (especially Section I: A holistic workflow)\n* Bryan J. STAT545 (based on the UBC course of the same name). <https://stat545.com>\n* Bryan J. Happy Git and GitHub for the useR. <https://happygitwithr.com>\n* For targets:\n  * McBain M. Benefits of a function-based diet (The {drake} post). <https://milesmcbain.xyz/the-drake-post/>\n    * Refers to the `drake` package, which was a predecessor package of `targets`. The same concepts all apply\n  * Landau W. The \\{targets\\} R package user manual. <https://books.ropensci.org/targets/>\n\n# Writing reports in R {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Data workflow\n\n![](images/linear-workflow.png){.absolute top=180 height=400 width=1500}\n\n![](images/workflow-arrows.png){.absolute .fragment top=55}\n\n::: {.absolute .fragment top=100 left=500 width=850 style=\"background:#F2F2F233;\"}\n```{.r}\nplan <- list(\n  tar_file(words, download_words()),\n  tar_target(frequency_table, summarise_word_lengths(words)),\n  tar_target(histogram, create_histogram(frequency_table)),\n  tar_file(report, render_report(\"reports/report.rmd\", frequency_table, histogram))\n)\n```\n:::\n\n::: {.absolute .fragment top=400 left=-100 width=500 style=\"background:#FFC20FCC; font-size:0.8em;\"}\nAdvantages:\n\n* Reported results are always kept up-to-date with data and analysis\n* Changes at any point along the workflow can be made easily and robustly\n:::\n\n---\n\n\n{{< video https://youtu.be/s3JldKoA0zw width=\"100%\" height=\"100%\" >}}\n\n\n\n## Data workflow\n\n![](images/linear-workflow.png){.absolute top=180 height=400 width=1500}\n\n![](images/workflow-arrows.png){.absolute top=55}\n\n::: {.absolute top=100 left=500 width=850 style=\"background:#F2F2F233;\"}\n```{.r}\nplan <- list(\n  tar_file(words, download_words()),\n  tar_target(frequency_table, summarise_word_lengths(words)),\n  tar_target(histogram, create_histogram(frequency_table)),\n  tar_file(report, render_report(\"reports/report.rmd\", frequency_table, histogram))\n)\n```\n:::\n\n::: {.absolute top=400 left=-100 width=500 style=\"background:#FFC20FCC; font-size:0.8em;\"}\nAdvantages:\n\n* Reported results are always kept up-to-date with data and analysis\n* Changes at any point along the workflow can be made easily and robustly\n:::\n\n## R Markdown\n\n\n{{< video https://vimeo.com/178485416?embedded=true&source=video_title&owner=22717988 width=\"100%\" height=\"85%\" >}}\n\n\n\n## Quarto\n\n* We'll focus on Quarto instead\n* Quarto is a relatively new tool very similar to RMarkdown\n  * Most of what you might read about RMarkdown also applies to Quarto\n  * see also <https://quarto.org> for documentation and guides\n\n---\n\n\n\n# Version control {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n# Automation {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n# Programming in R {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n",
    "supporting": [
      "CMOR-intro-to-R_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}