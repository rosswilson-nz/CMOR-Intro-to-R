{
  "hash": "0413145ae2060224d0949da3e4eaca9a",
  "result": {
    "markdown": "---\ntitle: \"Introduction to R\"\nsubtitle: \"CMOR Lunch'n'Learn\"\nauthor: \"Ross Wilson\"\ndate: \"2023-03-08\"\ndate-format: \"D MMMM YYYY\"\nformat:\n  revealjs:\n    theme: [default, cmor.scss]\n    title-slide-attributes: \n      data-background-image: \"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\"\n      data-background-size: \"7%, 25%, 100%\"\n      data-background-position: \"3% 1%, bottom 1% left 50px,0 0\"\n      data-background-repeat: \"no-repeat\"\n    template-partials:\n      - styles.html\n      - title-slide.html\n    preview-links: auto\n    margin: 0.2\n---\n\n\n\n\n\n# Getting Started {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## What is R? What is RStudio?\n\n- R is a *programming language* designed to undertake statistical analysis\n- RStudio is an Integrated Development Environment (IDE) for R\n  - An IDE is a piece of software including a text editor and other tools to make programming (in this case programming in R, specifically) easier\n  - You donâ€™t need to use RStudio to use R, but it makes it ***a lot*** easier\n  - To use RStudio, you also need R installed and working\n\n## Why learn R?\n\n- Powerful and extensible\n  - Pretty much any statistical analysis you want to do can be done in R\n  - There are a huge number of freely-available user-written packages that provide all sorts of additional functionality\n- Reproducibility\n  - By writing R scripts (code) for your analyses, they can be easily checked/replicated/ updated/adapted, by yourself and others\n- High-quality graphics\n  - R has a lot of plotting functions to help you produce publication-quality figures\n\n\n## Getting set up\n\n- Install R\n  - <https://cloud.R-project.org/>\n  - Choose the appropriate version for your operating system and follow the instructions\n- Install RStudio\n  - <https://posit.co/download/rstudio-desktop/>\n  - ditto\n\n## Getting to know RStudio\n\n:::{.absolute}\n![](images/rstudio-screenshot.png)\n:::\n\n:::{.fragment}\n:::{.absolute top=\"155\" left=\"0\" width=\"609\" height=\"161\" style=\"border-style:solid; border-width:5px; border-color:red; background: rgba(255, 255, 255, 0.4);\"}\n:::\n:::{.absolute top=\"205\" left=\"0\" width=\"609\" height=\"50\" style=\"text-align:center; color:red; font-weight:bold;\"}\nSource\n:::\n:::\n\n:::{.fragment}\n:::{.absolute top=\"321\" left=\"0\" width=\"609\" height=\"311\" style=\"border-style:solid; border-width:5px; border-color:red; background: rgba(255, 255, 255, 0.4);\"}\n:::\n:::{.absolute top=\"425\" left=\"0\" width=\"609\" style=\"text-align:center; color:red; font-weight:bold;\"}\nConsole\n:::\n:::\n\n:::{.fragment}\n:::{.absolute top=\"155\" left=\"614\" width=\"373\" height=\"180\" style=\"border-style:solid; border-width:5px; border-color:red; background: rgba(255, 255, 255, 0.4);\"}\n:::\n:::{.absolute top=\"190\" left=\"614\" width=\"373\" style=\"text-align:center; color:red; font-weight:bold;\"}\nEnvironment/<br>History\n:::\n:::\n\n:::{.fragment}\n:::{.absolute top=\"340\" left=\"614\" width=\"373\" height=\"292\" style=\"border-style:solid; border-width:5px; border-color:red; background: rgba(255, 255, 255, 0.4);\"}\n:::\n:::{.absolute top=\"405\" left=\"614\" width=\"373\" style=\"text-align:center; color:red; font-weight:bold;\"}\nFiles/Plots/<br>Packages/<br>Help/Viewer\n:::\n:::\n\n## Starting with R\n\n. . .\n\n- We can type math in the console, and get an answer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n3+5\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8\n```\n:::\n:::\n\n\n. . .\n\n- But to do anything useful, we need to assign the result to a name:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|2\"}\nx <- 3 + 5\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8\n```\n:::\n:::\n\n\n![](images/environment-pane.png){.absolute .fragment top=300 left=250}\n\n## Starting with R\n\n. . .\n\n- Then we can do things with them:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- 2 * x\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 16\n```\n:::\n:::\n\n\n![](images/environment-pane-2.png){.absolute .fragment top=115 left=250}\n\n. . .\n\n<br>\n\n- But note that once the value is assigned to y, changing x will not update y:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 25\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 16\n```\n:::\n:::\n\n\n## Functions\n\n- Functions allow us to run commands other than simple arithmetic\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\n- Functions consist of a set of input *arguments*, code that does something with those inputs, and a return *value*\n\n. . .\n\n- To get help on a function, look up the documentation\n\n```{.r}\n?sqrt\n```\n\n![](images/function-documentation.png){.absolute .fragment top=10 left=500}\n\n## Functions\n\n- You can (and should!) also write your own functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntimes2 <- function(a) {\n\treturn(a * 2)\n}\ntimes2(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 50\n```\n:::\n:::\n\n\n. . .\n\n- Separating your code out into discrete functions makes it\n  - shorter\n  - easier to follow\n  - less error prone\n\n## Data types\n\n- So far we have only seen single numeric values\n- Data in R can take many forms\n  - The most basic data structure is the *vector*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- c(3, 7, 10, 6)\nz\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  3  7 10  6\n```\n:::\n:::\n\n\n. . .\n\n- Vectors can also contain characters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(\"apple\", \"banana\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"apple\"  \"banana\"\n```\n:::\n:::\n\n\n:::{.absolute .fragment .smaller top=400 left=300 width=500 style=\"background:#ffffff; border-style:solid; border-width:medium; border-color:red; font-size:0.7em;\"}\n**The quotes are essential:**\n\notherwise R will look for the names 'apple' and 'banana' (if these names exist, it will use the values they refer to instead of the character strings; if they don't, it will give an error)\n:::\n\n## Data types\n\n- The basic data types are `numeric`, `character`, `logical` (`TRUE` and `FALSE` values only), and `integer`\n  - Also `complex` and `raw`, but we don't need to worry about those\n- In addition to vectors, more complex data structures include:\n  - lists: similar to vectors, but the elements can be anything (including other lists), and don't need to all be the same\n  - matrices and arrays: like vectors, but with multiple dimensions\n  - data frames: more on these later\n\n## Subsetting\n\n- We can extract values from within a vector (or other data structure) with square brackets\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- c(4, 2, 5, 12)\na[c(4, 2)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12  2\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\na[c(TRUE, FALSE, TRUE, FALSE)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4 5\n```\n:::\n:::\n\n\n- We can use this in conjunction with a logical operator to do conditional subsetting\n\n\n::: {.cell}\n\n```{.r .cell-code}\na[a > 4]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  5 12\n```\n:::\n:::\n\n\n# Working with Data Frames {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Data frames\n\n- A data frame is a tabular data structure (like a spreadsheet)\n  - Each column is a variable\n  - Each row is an observation\n- Each column (variable) is a vector, so must contain a single data type\n  - But different columns can have different types\n- We can read data from Excel or CSV spreadsheets, data files from Stata etc, previously saved R data frames, and much else...\n\n## The `tidyverse`\n\n- The '`tidyverse`' is a collection of packages created by the company that makes RStudio\n- It contains a lot of functions designed to make working with data frames easier\n  - `tibble`: a replacement for base data frames\n  - `readr`: read tabular data like csv files (also `readxl` for Excel files, `haven` for SPSS/Stata/SAS, and others for different file types)\n  - `dplyr`: data manipulation\n  - `tidyr`: reshaping and tidying data\n  - `ggplot2`: creating plots\n  - `purrr`: functional programming\n  - `stringr`: working with character strings\n  - `forcats`: working with factor variables\n\n## Data frames\n\n- Reading in a data frame with `read_csv()`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ngapminder <- read_csv(here::here(\"raw_data/gapminder_data.csv\"))\ngapminder\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 6\n   country      year      pop continent lifeExp gdpPercap\n   <chr>       <dbl>    <dbl> <chr>       <dbl>     <dbl>\n 1 Afghanistan  1952  8425333 Asia         28.8      779.\n 2 Afghanistan  1957  9240934 Asia         30.3      821.\n 3 Afghanistan  1962 10267083 Asia         32.0      853.\n 4 Afghanistan  1967 11537966 Asia         34.0      836.\n 5 Afghanistan  1972 13079460 Asia         36.1      740.\n 6 Afghanistan  1977 14880372 Asia         38.4      786.\n 7 Afghanistan  1982 12881816 Asia         39.9      978.\n 8 Afghanistan  1987 13867957 Asia         40.8      852.\n 9 Afghanistan  1992 16317921 Asia         41.7      649.\n10 Afghanistan  1997 22227415 Asia         41.8      635.\n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - `select()` only a subset of variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(gapminder, year, country, gdpPercap)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 3\n    year country     gdpPercap\n   <dbl> <chr>           <dbl>\n 1  1952 Afghanistan      779.\n 2  1957 Afghanistan      821.\n 3  1962 Afghanistan      853.\n 4  1967 Afghanistan      836.\n 5  1972 Afghanistan      740.\n 6  1977 Afghanistan      786.\n 7  1982 Afghanistan      978.\n 8  1987 Afghanistan      852.\n 9  1992 Afghanistan      649.\n10  1997 Afghanistan      635.\n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - `filter()` only a subset of observations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(gapminder, continent == \"Europe\", year == 2007)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 x 6\n   country                 year      pop continent lifeExp gdpPercap\n   <chr>                  <dbl>    <dbl> <chr>       <dbl>     <dbl>\n 1 Albania                 2007  3600523 Europe       76.4     5937.\n 2 Austria                 2007  8199783 Europe       79.8    36126.\n 3 Belgium                 2007 10392226 Europe       79.4    33693.\n 4 Bosnia and Herzegovina  2007  4552198 Europe       74.9     7446.\n 5 Bulgaria                2007  7322858 Europe       73.0    10681.\n 6 Croatia                 2007  4493312 Europe       75.7    14619.\n 7 Czech Republic          2007 10228744 Europe       76.5    22833.\n 8 Denmark                 2007  5468120 Europe       78.3    35278.\n 9 Finland                 2007  5238460 Europe       79.3    33207.\n10 France                  2007 61083916 Europe       80.7    30470.\n# ... with 20 more rows\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - `mutate()` to create new variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmutate(gapminder, gdp_billion = gdpPercap * pop / 10^9)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 7\n   country      year      pop continent lifeExp gdpPercap gdp_billion\n   <chr>       <dbl>    <dbl> <chr>       <dbl>     <dbl>       <dbl>\n 1 Afghanistan  1952  8425333 Asia         28.8      779.        6.57\n 2 Afghanistan  1957  9240934 Asia         30.3      821.        7.59\n 3 Afghanistan  1962 10267083 Asia         32.0      853.        8.76\n 4 Afghanistan  1967 11537966 Asia         34.0      836.        9.65\n 5 Afghanistan  1972 13079460 Asia         36.1      740.        9.68\n 6 Afghanistan  1977 14880372 Asia         38.4      786.       11.7 \n 7 Afghanistan  1982 12881816 Asia         39.9      978.       12.6 \n 8 Afghanistan  1987 13867957 Asia         40.8      852.       11.8 \n 9 Afghanistan  1992 16317921 Asia         41.7      649.       10.6 \n10 Afghanistan  1997 22227415 Asia         41.8      635.       14.1 \n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - `summarise()` to calculate summary statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarise(gapminder, mean_gdpPercap = mean(gdpPercap))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 1\n  mean_gdpPercap\n           <dbl>\n1          7215.\n```\n:::\n:::\n\n\n. . .\n\n - This is most useful in conjunction with `group_by()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarise(group_by(gapminder, continent),\n\t\t\t\t\tmean_gdpPercap = mean(gdpPercap))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  continent mean_gdpPercap\n  <chr>              <dbl>\n1 Africa             2194.\n2 Americas           7136.\n3 Asia               7902.\n4 Europe            14469.\n5 Oceania           18622.\n```\n:::\n:::\n\n\n## Manipulating data frames with `dplyr`\n\n  - The power of `dplyr` is in combining several commands using 'pipes'\n  \n  - The previous command could be written:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder %>% \n\tgroup_by(continent) %>% \n\tsummarise(mean_gdpPercap = mean(gdpPercap))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  continent mean_gdpPercap\n  <chr>              <dbl>\n1 Africa             2194.\n2 Americas           7136.\n3 Asia               7902.\n4 Europe            14469.\n5 Oceania           18622.\n```\n:::\n:::\n\n\n## Reshaping data frames\n\n- Previously we said that data frames have variables in columns and observations in rows\n- There may be different ways to interpret this in any given dataset\n  - Our dataset has country-by-year as the observation, and population, life expectancy, and GDP per capita as variables\n  - Sometimes it might make sense to have one row per country (observation), and multiple variables representing years\n  - These are known as 'long' and 'wide' format, respectively\n\n## Reshaping data frames\n\n- The `tidyr` package helps us transform our data from one shape to the other\n  + `pivot_wider()` takes a long dataset and makes it wider\n  + `pivot_longer()` takes a wide dataset and makes it longer\n- Recall our original dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 6\n   country      year      pop continent lifeExp gdpPercap\n   <chr>       <dbl>    <dbl> <chr>       <dbl>     <dbl>\n 1 Afghanistan  1952  8425333 Asia         28.8      779.\n 2 Afghanistan  1957  9240934 Asia         30.3      821.\n 3 Afghanistan  1962 10267083 Asia         32.0      853.\n 4 Afghanistan  1967 11537966 Asia         34.0      836.\n 5 Afghanistan  1972 13079460 Asia         36.1      740.\n 6 Afghanistan  1977 14880372 Asia         38.4      786.\n 7 Afghanistan  1982 12881816 Asia         39.9      978.\n 8 Afghanistan  1987 13867957 Asia         40.8      852.\n 9 Afghanistan  1992 16317921 Asia         41.7      649.\n10 Afghanistan  1997 22227415 Asia         41.8      635.\n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Reshaping data frames\n\n- We can reshape this to be wider (one row per country)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder_wide <- gapminder %>% \n  pivot_wider(id_cols = c(country, continent),\n              names_from = year, values_from = c(pop, lifeExp, gdpPercap))\ngapminder_wide\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 142 x 38\n   country     continent pop_1952 pop_1957 pop_1962 pop_1967 pop_1972 pop_1977\n   <chr>       <chr>        <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n 1 Afghanistan Asia       8425333  9240934 10267083 11537966 13079460 14880372\n 2 Albania     Europe     1282697  1476505  1728137  1984060  2263554  2509048\n 3 Algeria     Africa     9279525 10270856 11000948 12760499 14760787 17152804\n 4 Angola      Africa     4232095  4561361  4826015  5247469  5894858  6162675\n 5 Argentina   Americas  17876956 19610538 21283783 22934225 24779799 26983828\n 6 Australia   Oceania    8691212  9712569 10794968 11872264 13177000 14074100\n 7 Austria     Europe     6927772  6965860  7129864  7376998  7544201  7568430\n 8 Bahrain     Asia        120447   138655   171863   202182   230800   297410\n 9 Bangladesh  Asia      46886859 51365468 56839289 62821884 70759295 80428306\n10 Belgium     Europe     8730405  8989111  9218400  9556500  9709100  9821800\n# ... with 132 more rows, and 30 more variables: pop_1982 <dbl>,\n#   pop_1987 <dbl>, pop_1992 <dbl>, pop_1997 <dbl>, pop_2002 <dbl>,\n#   pop_2007 <dbl>, lifeExp_1952 <dbl>, lifeExp_1957 <dbl>, lifeExp_1962 <dbl>,\n#   lifeExp_1967 <dbl>, lifeExp_1972 <dbl>, lifeExp_1977 <dbl>,\n#   lifeExp_1982 <dbl>, lifeExp_1987 <dbl>, lifeExp_1992 <dbl>,\n#   lifeExp_1997 <dbl>, lifeExp_2002 <dbl>, lifeExp_2007 <dbl>,\n#   gdpPercap_1952 <dbl>, gdpPercap_1957 <dbl>, gdpPercap_1962 <dbl>, ...\n```\n:::\n:::\n\n\n## Reshaping data frames\n\n- Often raw data will come in a wide format, and we want to reshape it longer for data analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder_wide %>% \n  pivot_longer(pop_1952:gdpPercap_2007,\n               names_to = c(\".value\", \"year\"), names_sep = \"_\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 x 6\n   country     continent year       pop lifeExp gdpPercap\n   <chr>       <chr>     <chr>    <dbl>   <dbl>     <dbl>\n 1 Afghanistan Asia      1952   8425333    28.8      779.\n 2 Afghanistan Asia      1957   9240934    30.3      821.\n 3 Afghanistan Asia      1962  10267083    32.0      853.\n 4 Afghanistan Asia      1967  11537966    34.0      836.\n 5 Afghanistan Asia      1972  13079460    36.1      740.\n 6 Afghanistan Asia      1977  14880372    38.4      786.\n 7 Afghanistan Asia      1982  12881816    39.9      978.\n 8 Afghanistan Asia      1987  13867957    40.8      852.\n 9 Afghanistan Asia      1992  16317921    41.7      649.\n10 Afghanistan Asia      1997  22227415    41.8      635.\n# ... with 1,694 more rows\n```\n:::\n:::\n\n\n## Other `tidyverse` packages\n\n- We'll come back to data visualisation with `ggplot2` in a later session\n- `purrr` provides tools for functional programming\n  - If we have several similar datasets, or subgroups within our dataset, we don't want to write out/copy-and-paste our code separately for each one\n  - With `purrr`, we can use `map()` (and similar) to apply a function to multiple inputs and extract all of the outputs\n- `stringr` and `forcats` are worth looking at if you need to work with string or factor variables -- we won't cover them here\n\n## Resources\n\n- This material was adapted from the Data Carpentries' 'R for Social Scientists' course (<https://preview.carpentries.org/r-socialsci/index.html>)\n- Hands-On Programming with R (<https://rstudio-education.github.io/hopr>)\n  - An introduction to programming in R (for non-programmers!)\n- R for Data Science (<https://r4ds.hadley.nz>)\n  - An excellent practical introduction to using the tidyverse\n- Advanced R (<https://adv-r.hadley.nz>) and R Packages (<https://r-pkgs.org>)\n  - More advanced -- good next steps once you're a bit more comfortable using R\n\n# Data analysis in R (regression) {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Everything in R is an object\n\n. . .\n\n* This includes your fitted regression models\n\n. . .\n\n* Workflow:\n  * Import/tidy/manipulate raw data\n  * Run regression or other models\n  * Use the created model objects\n    * print to console\n    * save to file\n    * extract coefficient estimates\n    * plot results\n    * export to excel/word\n    * etc.\n\n## Fitted model objects\n\n* R has evolved over time to fit a variety of different needs and use cases\n\n* This gives it great flexibility and ability to meet the needs of different users\n\n* But, the diversity of interfaces, data structures, implementation, and fitted model objects can be a challenge\n  * There is often more than one way to fit a given model\n  * What you've learned about one model implemented in a given package may not translate well to working with other functions/packages\n\n* We'll cover some tools to help bridge that gap\n\n## Fitted model objects\n\n* A few common (but not universal) features:\n\n* Models are described by a `formula`: e.g. `y ~ x + z`\n\n* Data are provided in a data frame (or, equivalently, tibble)\n\n* `coef()`, `vcov()`, `summary()` can be used to extract the coefficient estimates, variance covariance matrix, and to print a summary of the fitted model\n\n## The `broom` package\n\n* `broom` provides several functions to convert fitted model objects to tidy tibbles\n\n* The package works with several model fitting functions from base R and commonly-used packages\n\n  * Some other packages may also implement their own methods to work with these functions\n\n* Functions:\n  * `tidy()`: construct a tibble that summarises the statistical findings (coefficients, p-values, etc.)\n  * `augment()`: add new columns to the original data (predictions/fitted values, etc.)\n  * `glance()`: construct a one-row summary of the model (goodness-of-fit, etc.)\n\n## First example -- linear regression\n\n* Linear regression models can be fitted with the `lm` function (in the `stats` package, part of base R)\n\n\n* We'll start by loading the gapminder dataset from the previous session:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ngapminder <- read_csv(here::here(\"raw_data/gapminder_data.csv\"))\n```\n:::\n\n\n## First example -- linear regression\n\n* Use `?lm` to find the documentation\n\n\n:::{.fragment fragment-index=2}\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlinear_regression_model <- lm(lifeExp ~ gdpPercap, gapminder)\nlinear_regression_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = lifeExp ~ gdpPercap, data = gapminder)\n\nCoefficients:\n(Intercept)    gdpPercap  \n  5.396e+01    7.649e-04  \n```\n:::\n:::\n\n:::\n\n![](images/lm-documentation.png){.absolute .fragment fragment-index=1 top=50 left=700}\n\n## First example -- linear regression\n\n* `linear_regression_model` is now a fitted model object\n\n* If we want, we can look at how this object is actually stored:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(linear_regression_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 12\n $ coefficients : Named num [1:2] 5.40e+01 7.65e-04\n  ..- attr(*, \"names\")= chr [1:2] \"(Intercept)\" \"gdpPercap\"\n $ residuals    : Named num [1:1704] -25.8 -24.3 -22.6 -20.6 -18.4 ...\n  ..- attr(*, \"names\")= chr [1:1704] \"1\" \"2\" \"3\" \"4\" ...\n $ effects      : Named num [1:1704] -2455.1 311.1 -21.6 -19.6 -17.5 ...\n  ..- attr(*, \"names\")= chr [1:1704] \"(Intercept)\" \"gdpPercap\" \"\" \"\" ...\n $ rank         : int 2\n $ fitted.values: Named num [1:1704] 54.6 54.6 54.6 54.6 54.5 ...\n  ..- attr(*, \"names\")= chr [1:1704] \"1\" \"2\" \"3\" \"4\" ...\n $ assign       : int [1:2] 0 1\n $ qr           :List of 5\n  ..$ qr   : num [1:1704, 1:2] -41.2795 0.0242 0.0242 0.0242 0.0242 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : chr [1:1704] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. ..$ : chr [1:2] \"(Intercept)\" \"gdpPercap\"\n  .. ..- attr(*, \"assign\")= int [1:2] 0 1\n  ..$ qraux: num [1:2] 1.02 1.02\n  ..$ pivot: int [1:2] 1 2\n  ..$ tol  : num 1e-07\n  ..$ rank : int 2\n  ..- attr(*, \"class\")= chr \"qr\"\n $ df.residual  : int 1702\n $ xlevels      : Named list()\n $ call         : language lm(formula = lifeExp ~ gdpPercap, data = gapminder)\n $ terms        :Classes 'terms', 'formula'  language lifeExp ~ gdpPercap\n  .. ..- attr(*, \"variables\")= language list(lifeExp, gdpPercap)\n  .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:2] \"lifeExp\" \"gdpPercap\"\n  .. .. .. ..$ : chr \"gdpPercap\"\n  .. ..- attr(*, \"term.labels\")= chr \"gdpPercap\"\n  .. ..- attr(*, \"order\")= int 1\n  .. ..- attr(*, \"intercept\")= int 1\n  .. ..- attr(*, \"response\")= int 1\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. ..- attr(*, \"predvars\")= language list(lifeExp, gdpPercap)\n  .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n  .. .. ..- attr(*, \"names\")= chr [1:2] \"lifeExp\" \"gdpPercap\"\n $ model        :'data.frame':\t1704 obs. of  2 variables:\n  ..$ lifeExp  : num [1:1704] 28.8 30.3 32 34 36.1 ...\n  ..$ gdpPercap: num [1:1704] 779 821 853 836 740 ...\n  ..- attr(*, \"terms\")=Classes 'terms', 'formula'  language lifeExp ~ gdpPercap\n  .. .. ..- attr(*, \"variables\")= language list(lifeExp, gdpPercap)\n  .. .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : chr [1:2] \"lifeExp\" \"gdpPercap\"\n  .. .. .. .. ..$ : chr \"gdpPercap\"\n  .. .. ..- attr(*, \"term.labels\")= chr \"gdpPercap\"\n  .. .. ..- attr(*, \"order\")= int 1\n  .. .. ..- attr(*, \"intercept\")= int 1\n  .. .. ..- attr(*, \"response\")= int 1\n  .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. .. ..- attr(*, \"predvars\")= language list(lifeExp, gdpPercap)\n  .. .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n  .. .. .. ..- attr(*, \"names\")= chr [1:2] \"lifeExp\" \"gdpPercap\"\n - attr(*, \"class\")= chr \"lm\"\n```\n:::\n:::\n\n\n## First example -- linear regression\n\n* More usefully, we can print a summary of the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(linear_regression_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = lifeExp ~ gdpPercap, data = gapminder)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-82.754  -7.758   2.176   8.225  18.426 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 5.396e+01  3.150e-01  171.29   <2e-16 ***\ngdpPercap   7.649e-04  2.579e-05   29.66   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.49 on 1702 degrees of freedom\nMultiple R-squared:  0.3407,\tAdjusted R-squared:  0.3403 \nF-statistic: 879.6 on 1 and 1702 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## First example -- linear regression\n\n* If we want to work with the results or combine/compare them with other models, `tidy()` from the `broom` package will put them into a nice tidy tibble\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\ntidy(linear_regression_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept) 54.0      0.315         171.  0        \n2 gdpPercap    0.000765 0.0000258      29.7 3.57e-156\n```\n:::\n:::\n\n\n. . .\n\n* And `glance()` gives us several overall model statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(linear_regression_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik    AIC    BIC\n      <dbl>         <dbl> <dbl>     <dbl>     <dbl> <dbl>  <dbl>  <dbl>  <dbl>\n1     0.341         0.340  10.5      880. 3.57e-156     1 -6422. 12850. 12867.\n# ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\n# Data visualisation {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Data visualisation with `ggplot2`\n\n- There are a lot of tools available to create plots in R\n  - `ggplot2` is the most well-developed and widely used\n- We generally want data in long format for plotting\n  - One column for each variable\n  - One row for each observation\n- We'll use the `gapminder` dataset from the previous session\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ngapminder <- read_csv(here::here(\"raw_data/gapminder_data.csv\"))\n```\n:::\n\n\n## The grammar of graphics\n\n- dataset -- self-explanatory\n- geom -- the geometric object used to represent the data\n- mappings -- which features of the geom represent which variables in the data\n- stats -- transformations of the data before plotting\n- position -- to avoid overplotting data points\n- coordinate system -- how the x and y axes are plotted\n- faceting scheme -- split the plot by subgroups\n\n## Data visualisation with `ggplot2` {.smaller}\n\n- That's the theory\n- In practice, the easiest way is to build the plot up step-by-step (trial-and-error)\n  - start with the basic `ggplot` object\n\n```{.r}\nggplot(data = gapminder)\n```\n\n:::{.fragment fragment-index=1}\n![](images/ggplot-blank.png){.absolute .fragment fragment-index=2 .fade-out top=100 left=200 width=550 height=550}\n:::\n\n:::{.fragment fragment-index=2}\n- you can specify (some of) the mappings at this stage\n\n```{.r}\nggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))\n```\n:::\n\n::: {.fragment .fade-in fragment-index=3}\n![](images/ggplot-axes.png){.absolute .fragment .fade-out top=100 left=200 width=550 height=550}\n:::\n\n# Data analysis workflows and project organisation {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Reproducible research\n\n* What is 'reproducibility'?\n  * Focus here is on *computational reproducibility* -- can your results be replicated by someone (or yourself!) with access to your data, code, etc.\n\n* Why might research not be reproducible?\n  * Raw data are not available or have been changed\n  * Intermediate steps taken to extract, clean, reshape, merge, or analyse data are not adequately recorded or described\n  * Software tools have changed or are no longer available since the analysis was conducted\n  * Errors in manually transcribing results from analysis software to final report (manuscript, etc.)\n\n## Reproducible research\n\n* Ensuring reproducibility (for others) can also have great benefits for you as the analyst/author\n  * When you come back to an analysis later, you know exactly what you did, why you did it, and how to replicate it if needed\n  * If data changes, errors are identified, or new analyses need to be conducted, your analysis and results can easily be updated\n  * The code and methods used in one project/analysis can be re-used in other work\n  * Keeping to a simple, standardised workflow for all projects allows you to switch easily & quickly between projects\n    * And prevents you having to make a whole bunch of new decisions every time you start something new\n\n---\n\n![](images/interconnected-tasks.png)\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles -- Raw data\n\n* Raw data stays raw\n  * Make raw data files read-only\n  \n## Key principles - Raw data\n\n![](images/read-only.png)\n\n## Key principles -- Raw data\n\n* Raw data stays raw\n  * Make raw data files read-only\n  * Can be relaxed (temporarily) if needed, but avoids accidental changes\n  * Most (probably all) changes to data should be scripted (in R, Stata, etc.) rather than made directly in raw data files\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles\n\n* Raw data stays raw\n* [Source is real]{style=\"color:Red;\"}\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles -- Source files\n\n* Source is real...\n  * ...workspace is replaceable\n* Any individual R session is disposable and can be replaced/recreated at any time, if you have raw data and appropriate source code\n* Thinking in this way forces you to follow good reproducibility practices in your analysis workflow\n\n## Key principles -- Source files\n\n* What does 'Source is real' mean?\n  * Data import, cleaning, reshaping, wrangling, and analysis should all be conducted via script files\n    * or at least documented in thorough, step-by-step detail\n  * All source code should be saved (regularly!) so all of these steps can be reproduced at any time\n  * Important (or time-consuming) intermediate objects (cleaned datasets, figures, etc) should be explicitly saved, individually, to files (by script, not the mouse, if possible)\n\n## Key principles -- Source files\n\n* Start R with a blank slate, and restart often\n\n## Key principles -- Source files\n\n![](images/save-workspace.PNG)\n\n:::{.absolute top=\"330\" left=\"130\" width=\"260\" height=\"72\" style=\"border-style:solid; border-width:5px; border-color:red;\"}\n:::\n\n## Key principles -- Source files\n\n* Start R with a blank slate, and restart often\n  * When you are running code interactively to try things out, you will be adding objects to the workspace, loading packages, etc\n  * If you inadvertently rely on these objects, packages, etc in your source files, you may not be able to reproduce your results in a new session later\n  * If you have saved source code and intermediate objects to file as you go, it is quick and easy to restart R (Ctrl+Shift+F10, in RStudio) regularly to check whether everything still works as expected\n    * It is much better to find this out after a few minutes than after a whole dayâ€™s work!\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* [Design for collaboration]{style=\"color:Red;\"}\n  * [(including with your future self)]{style=\"color:Red;\"}\n* Consider version control\n* Automation?\n\n## Key principles -- Design for collaboration\n\n. . .\n\n* An analysis directory like this makes it very difficult for anyone (including yourself later) to follow the steps required to reproduce your results\n\n---\n\n![](images/bad_layout.png)\n\n## Key principles -- Design for collaboration\n\n:::{.columns}\n\n::: {.column}\n* Much better to follow a logical structure (and the same across all of your projects)\n  * Set out high-level structure, e.g.\n    1. read raw data\n    2. tidy data for analysis\n    3. run analyses on tidy data\n    4. collate report/results of analyses\n  * Put raw data in its own directory (and read-only)\n  * Consider other structures/subfolders as appropriate for your project\n:::\n\n:::{.column}\n![](images/better-layout.png)\n:::\n\n:::\n\n## Key principles -- Design for collaboration\n\n* Break up complicated or repeated analysis steps into discrete functions\n* Give functions and variables meaningful names\n* Use comments liberally\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* [Consider version control]{style=\"color:Red;\"}\n* Automation?\n\n## Key principles -- Version control\n\n* Keeping track of changes to data and code (and being able to revert to a previous version if things go wrong) is critical for reproducible research\n\n* This is particularly true when collaborating with others\n\n* The best way to do this is with a version control system such as Git\n\n## Key principles -- Version control\n\n* We won't go into this in detail today, but a quick Getting Started guide:\n  * Register a GitHub account (<https://github.com>)\n  * Install Git (<https://git-scm.com>) and complete basic setup\n  * Get a Git client (GUI)\n    * GitKraken is a good choice (<https://gitkraken.com>)\n    * GitHub offers a free client, GitHub Desktop (<https://desktop.github.com/>)\n    * RStudio has a basic Git client built-in, which is fine for much day-to-day use\n* See <https://happygitwithr.com/> for more detailed instructions\n\n## Key principles -- Version control\n\n* Using Git (& GitHub) in your projects\n  * A couple of ways to get this set up. Probably the easiest is:\n  * Create a project repository (repo) on GitHub\n  * Import ('clone') the repo as a new RStudio project\n  * Make changes as usual in RStudio (or nay other program)\n  * 'Commit' (take a snapshop of the current state of the project) often to your local repo\n  * Less often (maybe once/day) 'push' (sync) the local repo to GitHub\n* What to put under version control\n  * Source code\n  * Raw data (unless its very large)\n\n:::{.absolute .fragment top=480 left=500 width=500 style=\"background:#ffffff; border-style:solid; border-width:medium; border-color:red; font-size:0.9em; margin-left:20px; line-height:0.9;\"}\nWhat **not** to put under version control\n\n* Most intermediate objects\n* Miscellaneous supporting documents (pdf files, etc.)\n* Final output in the form of word documents, etc.\n:::\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* Automation?\n\n## Key principles\n\n* Raw data stays raw\n* Source is real\n* Design for collaboration\n  * (including with your future self)\n* Consider version control\n* [Automation?]{style=\"color:Red;\"}\n\n## Key principles -- Automation\n\n* Just as we treat source code as the â€˜trueâ€™, reproducible record of each step of the analysis, we can record (and automate) how the sequence of individual steps fits together to produce our final results\n\n::: {.fragment fragment-index=1}\n::: {.fragment .fade-out fragment-index=2}\n![](images/workflow.png){.absolute top=100 left=333}\n:::\n:::\n\n:::{.fragment fragment-index=2}\n\n* Can be as simple as something like:\n\n\t```{.r}\n\tsource(\"code/00-download-data.R\")\n\tsource(\"code/01-tabulate-frequencies.R\")\n\tsource(\"code/02-create-histogram.R\")\n\tsource(\"code/03-render-report.R\")\n\t```\n\n* Shows in what order to run the scripts, and allows us to resume from the middle (if, for example, you have only changed the file `02-create-histogram.R`, there is no need to redo the first two steps, but we do need to rerun the `create-histogram` and `render-report` steps\n  * Each script should load the required inputs and save the resulting output to file\n\n:::\n\n## Key principles -- Automation\n\n* For more complicated (or long-running) analyses, we may want to explicitly specify dependencies and let the computer figure out how to get everything up-to-date\n\n* Two good tools for doing this:\n  * make\n  * targets\n\n* Advantages of an automated pipeline like this:\n  * When you modify one stage of the pipeline, you can re-run your analyses to get up-to-date final results, with a single click/command\n  * Only the things that need to be updated will be re-run, saving time (important if some of your analyses take a long time to run)\n\n## Key principles -- Automation\n\n* Make is a system tool, designed for use in software development, to specify targets, commands, and dependencies between files and selectively re-run commands when dependencies change\n\n* A Makefile is a plain text file specifying a list of these targets (intermediate/output files in the analysis workflow), commands (to create the targets), and dependencies (input files needed for each command)\n\n```{.bash}\nwords.txt: /usr/share/dict/words\n\tcp /usr/share/dict/words words.txt\n\nhistogram.tsv: histogram.r words.txt\n\tRscript $<\n\nhistogram.png: histogram.tsv\n\tRscript -e 'library(ggplot2); qplot(Length, Freq, data=read.delim(\"$<\")); ggsave(\"$@\")'\n\nreport.html: report.rmd histogram.tsv histogram.png\n\tRscript -e 'rmarkdown::render(\"$<\")'\n```\n\n## Key principles -- Automation\n\n* `targets` is an R package designed to do something very similar, but specifically designed for R projects\n\n```{.r}\nplan <- list(\n  tar_file(words, download_words()),\n  tar_target(frequency_table, summarise_word_lengths(words)),\n  tar_target(histogram, create_histogram(frequency_table)),\n  tar_file(report, render_report(\"reports/report.rmd\", frequency_table, histogram))\n)\n```\n\n* Abstract workflow steps behind function calls (with meaningful names) as much as possible\n  * The plan should be a clear, high-level overview of the analysis steps required\n\n## Summary\n\n* Treat raw data as read-only\n* Save source, not the workspace\n* Design for collaboration\n  * Follow a logical project structure\n  * Simplify code with human-readable abstractions (functions etc)\n* Consider version control\n* Consider automating your analyses\n\n---\n\n![](images/owl.jpg)\n\n## Summary\n\n* Treat raw data as read-only ![](images/tick.jpg){style=\"height:1em\"}\n* Save source, not the workspace ![](images/tick.jpg){style=\"height:1em\"}\n* Design for collaboration\n  * Follow a logical project structure ![](images/tick.jpg){style=\"height:1em\"}\n  * Simplify code with human-readable abstractions (functions etc) ![](images/tick.jpg){style=\"height:1em\"}\n* Consider version control\n* Consider automating your analyses\n\n:::{.absolute top=120 left=540 style=\"color:#0070c0; font-size:0.6em; line-height:0.6em;\"}\n(if you are already writing<br>script files for your analyses)\n:::\n\n:::{.absolute top=325 left=800 style=\"color:#0070c0; font-size:0.6em; line-height:0.6em;\"}\n(will get better<br>with practice)\n:::\n\n## Resources {.smaller}\n\n* Wilson G, Aruliah DA, Brown CT, Chue Hong NP, Davis M, et al. (2014) Best Practices for Scientific Computing. PLoS Biol 12(1):e1001745. <https://doi.org/10.1371/journal.pbio.1001745>\n* Wilson G, Bryan J, Cranston K, Kitzes J, Nederbragt L, Teal TK (2017) Good enough practices in scientific computing. PloS Comput Biol 13(6):e1005510. <https://doi.org/10.1371/journal.pcbi.1005510>\n* Bryan J, Hester J. What they forgot to teach you about R. <https://rstats.wtf> (especially Section I: A holistic workflow)\n* Bryan J. STAT545 (based on the UBC course of the same name). <https://stat545.com>\n* Bryan J. Happy Git and GitHub for the useR. <https://happygitwithr.com>\n* For targets:\n  * McBain M. Benefits of a function-based diet (The {drake} post). <https://milesmcbain.xyz/the-drake-post/>\n    * Refers to the `drake` package, which was a predecessor package of `targets`. The same concepts all apply\n  * Landau W. The \\{targets\\} R package user manual. <https://books.ropensci.org/targets/>\n\n# Writing reports in R {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n## Data workflow\n\n![](images/linear-workflow.png){.absolute top=180 height=400 width=1500}\n\n![](images/workflow-arrows.png){.absolute .fragment top=55}\n\n::: {.absolute .fragment top=100 left=500 width=850 style=\"background:#F2F2F233;\"}\n```{.r}\nplan <- list(\n  tar_file(words, download_words()),\n  tar_target(frequency_table, summarise_word_lengths(words)),\n  tar_target(histogram, create_histogram(frequency_table)),\n  tar_file(report, render_report(\"reports/report.rmd\", frequency_table, histogram))\n)\n```\n:::\n\n::: {.absolute .fragment top=400 left=-100 width=500 style=\"background:#FFC20FCC; font-size:0.8em;\"}\nAdvantages:\n\n* Reported results are always kept up-to-date with data and analysis\n* Changes at any point along the workflow can be made easily and robustly\n:::\n\n---\n\n\n{{< video https://youtu.be/s3JldKoA0zw width=\"100%\" height=\"100%\" >}}\n\n\n\n## Data workflow\n\n![](images/linear-workflow.png){.absolute top=180 height=400 width=1500}\n\n![](images/workflow-arrows.png){.absolute top=55}\n\n::: {.absolute top=100 left=500 width=850 style=\"background:#F2F2F233;\"}\n```{.r}\nplan <- list(\n  tar_file(words, download_words()),\n  tar_target(frequency_table, summarise_word_lengths(words)),\n  tar_target(histogram, create_histogram(frequency_table)),\n  tar_file(report, render_report(\"reports/report.rmd\", frequency_table, histogram))\n)\n```\n:::\n\n::: {.absolute top=400 left=-100 width=500 style=\"background:#FFC20FCC; font-size:0.8em;\"}\nAdvantages:\n\n* Reported results are always kept up-to-date with data and analysis\n* Changes at any point along the workflow can be made easily and robustly\n:::\n\n## R Markdown\n\n\n{{< video https://vimeo.com/178485416?embedded=true&source=video_title&owner=22717988 width=\"100%\" height=\"85%\" >}}\n\n\n\n## Quarto\n\n* We'll focus on Quarto instead\n* Quarto is a relatively new tool very similar to RMarkdown\n  * Most of what you might read about RMarkdown also applies to Quarto\n  * see also <https://quarto.org> for documentation and guides\n\n---\n\n\n\n# Version control {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n# Automation {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n\n# Programming in R {background-image=\"images/otago-pennant.png, images/cmor-banner.png, images/title-background.png\" background-size=\"7%, 25%, 100%\" background-repeat=\"no-repeat\" background-position=\"3% 1%, bottom 1% left 50px,0 0\" style=\"text-align:right;\"}\n",
    "supporting": [
      "CMOR-intro-to-R_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}